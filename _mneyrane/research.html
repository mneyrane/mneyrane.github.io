---
title: Research 
---

<h1>Research</h1>
<hr>

<p>
<strong class="text-warning">Note: my master's program is still in progress, so expect this page to update.</strong>
</p>


<h5 class="fw-bold">Main interests</h5>

<div class="row">
  <div class="col">
    <ul>
      <li>deep learning</li>
      <li>continuous optimization</li>
    </ul>
  </div>
  <div class="col">
    <ul>
      <li>optimal transport</li>
      <li>compressed sensing</li>
    </ul>
  </div>
  <div class="col">
    <ul>
      <li>numerical analysis</li>
      <li>partial differential equations</li>
    </ul>
  </div>
</div>


<h5 class="fw-bold text-info">Current research</h5>

<p>
My ongoing master's research is about developing <strong>stable, accurate, and efficient deep neural networks for compressive imaging</strong>.
</p>

<p>
To motivate this, in the past decade, deep learning has taken the world by storm, with unforeseen success in a myriad of (formerly) challenging applications, like image classification and natural language processing. Indicating great potential, there has been growing interest in applying deep learning to solve compressive imaging problems. Compressive imaging encompasses a wide range of scientific tasks, such as medical imaging, seismic imaging and electron microscopy to name a few. Up until recently, model-based methods served as state-of-the-art tools to tackle these problems.
Data-driven methods, like deep learning, have been found to empirically outperform model-based methods with superior accuracy on data, but suffer from hallucinations, instability, and poor generalization performance. This raises security and safety concerns for using deep learning in critical tasks like medical imaging. 
</p>

<p>
A natural question to ask is: <strong>can we compute deep neural networks for compressive imaging with state-of-the-art performance guarantees?</strong>
</p>

<p>
In collaboration with my supervisor <a href="https://benadcock.org/">Ben Adcock</a>, our research aims to address this question, taking inspiration from and building on <a href="https://arxiv.org/abs/2101.08286">FIRENETs</a>, a closely related work authored by Antun, Colbrook and Hansen. Our work touches upon several areas of mathematics, including convex optimization, compressed sensing, random matrix theory, and machine learning.
</p>



<h2 class="pt-3 fw-bold">Publications</h2>

{% assign pub1 = "submitted" %}
{% assign pub2 = "journal paper" %}
{% assign pub3 = "conference abstract" %}

{% for item in site.data.publications %}
  {% if item.type == pub1 %}
    {% include publication_section.html title="Submitted work" type=pub1 %}
    {% break %}
  {% endif %}
{% endfor %}

{% for item in site.data.publications %}
  {% if item.type == pub2 %}
    {% include publication_section.html title="Journal papers" type=pub2 %}
    {% break %}
  {% endif %}
{% endfor %}

{% for item in site.data.publications %}
  {% if item.type == pub3 %}
    {% include publication_section.html title="Conference abstracts" type=pub3 %}
    {% break %}
  {% endif %}
{% endfor %}

<h2 class="pt-3 fw-bold">Presentations</h2>

{% for item in site.data.presentations %}
  {% if item.scheduled %}
    {% include presentation_section.html title="Scheduled talks" scheduled=true %}
    {% break %}
  {% endif %}
{% endfor %}

{% for item in site.data.presentations %}
  {% if item.scheduled == nil %}
    {% include presentation_section.html title="Past talks" %}
    {% break %}
  {% endif %}
{% endfor %}
