---
title: Research 
---

<h1>Research</h1>
<hr>

<h2 class="fw-bold">Main interests</h2>

<div class="row">
  <div class="col">
    <ul>
      <li>machine learning</li>
      <li>data science</li>
    </ul>
  </div>
  <div class="col">
    <ul>
      <li>continuous optimization</li>
      <li>numerical analysis</li>
    </ul>
  </div>
  <div class="col">
    <ul>
      <li>compressed sensing</li>
      <li>reinforcement learning</li>
    </ul>
  </div>
  <div class="col">
    <ul>
      <li>optimal transport</li>
      <li>game theory</li>
  </div>
</div>


<h2 class="fw-bold">Master's research</h2>

<h5 class="fw-bold">Deep neural networks for inverse problems in imaging</h5>

<p> 
In the past decade, deep learning has been incredibly successful in a myriad of image processing applications. As a result, there has been growing interest in applying deep learning to solve inverse problems in imaging. For example, deep learning is being leveraged in <a href="https://doi.org/10.1109/JPROC.2019.2936204">medical imaging</a> to optimize sampling (to reduce scan times or radiation dose) and speed up reconstruction and inference. Being able to tackle imaging problems is fundamental to the progress of science, engineering and medicine. Despite recent work indicating that deep learning performs better than state-of-the-art model-based methods for imaging, deep neural networks have significant issues with stability and generalization. This raises the key question: <strong>can we construct deep neural networks for inverse problems in imaging with state-of-the-art performance guarantees?</strong>
</p>

<p>
My supervisor <a href="https://benadcock.org/">Ben Adcock</a> and I contribute towards answering this question by extending the work of <a href="https://doi.org/10.1073/pnas.2107151119">Matthew Colbrook, et al</a>. In a <a href="https://doi.org/10.1007/s43670-022-00043-5">paper</a>, we construct neural networks that achieve the same performance guarantees as state-of-the-art model-based methods to recover a class of analysis-sparse signals.
In my <a href="https://summit.sfu.ca/item/36038">master's thesis</a>, recovery of gradient-sparse signals is considered instead.
The neural network constructions are based on unrolling an optimization algorithm, which are made efficient by applying a <i>restart scheme</i> to accelerate the image reconstruction. This has led to interesting <a href="https://arxiv.org/abs/2301.02268">side work</a> with Ben Adcock and Matthew Colbrook to examine general parameter-free restart schemes for continuous optimization. 
</p>
<p>
Our work brings together several areas of mathematics, including convex optimization, compressed sensing, random matrix theory and deep learning.
</p>



<h2 class="pt-3 fw-bold">Publications</h2>

{% assign pub1 = "submitted" %}
{% assign pub2 = "journal paper" %}
{% assign pub3 = "conference abstract" %}
{% assign pub4 = "thesis" %}

{% for item in site.data.publications %}
  {% if item.type == pub1 %}
    {% include publication_section.html title="Submitted work" type=pub1 %}
    {% break %}
  {% endif %}
{% endfor %}

{% for item in site.data.publications %}
  {% if item.type == pub2 %}
    {% include publication_section.html title="Journal papers" type=pub2 %}
    {% break %}
  {% endif %}
{% endfor %}

{% for item in site.data.publications %}
  {% if item.type == pub3 %}
    {% include publication_section.html title="Conference abstracts" type=pub3 %}
    {% break %}
  {% endif %}
{% endfor %}

{% for item in site.data.publications %}
  {% if item.type == pub4 %}
    {% include publication_section.html title="Theses and dissertations" type=pub4 %}
    {% break %}
  {% endif %}
{% endfor %}


<h2 class="pt-3 fw-bold">Presentations</h2>

{% for item in site.data.presentations %}
  {% if item.scheduled %}
    {% include presentation_section.html title="Scheduled talks" scheduled=true %}
    {% break %}
  {% endif %}
{% endfor %}

{% for item in site.data.presentations %}
  {% if item.scheduled == nil %}
    {% include presentation_section.html title="Past talks" %}
    {% break %}
  {% endif %}
{% endfor %}
